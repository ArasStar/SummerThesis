# -*- coding: utf-8 -*-
"""self_supervised_relative_pos.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1avHohC4V-baYfAQZj5EHBtTmHeqFOeRa
"""

# %reload_ext autoreload
# %autoreload 2
# %matplotlib inline

#DOWNLOAD THE DATA

from google.colab import drive
import zipfile

#MOUNT GDRIVE: DOWNLOAD DATA AND FILTERED LABELS
drive.mount('/content/gdrive',force_remount=True)

# UNZIP ZIP
print ("Uncompressing zip file")
zip_ref = zipfile.ZipFile('/content/gdrive/My Drive/CheXpert-v1.0-small.zip', 'r')
zip_ref.extractall()
zip_ref.close()
print("downloaded files")

import sys #For Patch lib
sys.path.append("gdrive/My Drive/summerthesis/patch")

import os#for CUDA tracking
#from __future__ import print_function, division
import torch
import pandas as pd
from skimage.io import imread
#from skimage import io
import numpy as np
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
#MODELS
import re
import torch.nn as nn
import torch.nn.functional as F
import torchvision.models as models
import matplotlib.pyplot as plt

#Patch
import patch


# Ignore warnings
import warnings
warnings.filterwarnings("ignore")

class CheXpertDataset(Dataset):
    """Face Landmarks dataset."""

    def __init__(self, csv_file, root_dir, transform=None):
              
        super().__init__()

        self.observations_frame = pd.read_csv(csv_file)
        self.root_dir = root_dir
        self.transform = transform
        self.list_classes=['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Pleural Effusion']
        
    def __len__(self):
        return len(self.observations_frame)

    def __getitem__(self, idx):
        
        img_name = os.path.join(self.observations_frame.iloc[idx, 0])
        image = imread(img_name)
        image = transforms.ToPILImage()(image)
      

        observations=self.observations_frame.loc[idx,self.list_classes]
        observations = torch.from_numpy(observations.values.astype(np.float32))
        #np.float32()
        
     
        #RETURNING IMAGE AND LABEL SEPERATELY FOR TORCH TRANSFORM LIB
      
        if self.transform:
            
            image = self.transform(image)

        return image,observations

def chexpert_load(csv_file_name,transformation,batch_size):
  
  cheXpert_dataset = CheXpertDataset(csv_file=csv_file_name,
                                     root_dir='not used', transform=transformation)

  dataloader = DataLoader(cheXpert_dataset, batch_size=batch_size,shuffle=True)

  return cheXpert_dataset,dataloader



use_cuda = True
if use_cuda and torch.cuda.is_available():
    device = torch.device('cuda')
else:
    print("CUDA didn't work")
    device = torch.device('cpu')

x=torch.ones(16,1024)

x = torch.stack([torch.cat((x[idx,:],x[idx+1,:]))
                     for idx in range(0,16,2)], dim=0)

print(x.shape)



#HOW TO USE RES BLOCK AT THE END AS A Class there operations between features and classifier that causes dimension conflict
#LOSS FUNC JUST A 8 WAY SOFTMAX

class RelativePositionHead(torch.nn.Module):
    def __init__(self, D_in, D_out=8):
        """
        In the constructor we instantiate two nn.Linear modules and assign them as
        member variables.
        """
        super(RelativePositionHead, self).__init__()
        self.res_block1 = models.resnet.BasicBlock(D_in,512)
        self.res_block2 = models.resnet.BasicBlock(512,512)
        self.classifier = torch.nn.Linear(512,D_out)

    def forward(self, x):
        
        #print(x.shape)
        x = self.res_block1(x)
        x = self.res_block2(x)
        
        _,N,_,_ = x.shape
        # combining two representation (batch is [bs,ch,h,w ])
        x = torch.stack([torch.cat((x[idx,:,:,:],x[idx+1,:,:,:]))
                     for idx in range(0,N,2)], dim=0)
        
        #linear output with 8 outpts(directions)
        y_pred = self.classifier(x)
        return y_pred

      
      
class Basic_RelativePositionHead(torch.nn.Module):
    def __init__(self, D_in, D_out=8):
        """
        No task head just concating what comes out just before default classifer then applying linear
        In the constructor we instantiate two nn.Linear modules and assign them as
        member variables.
        """
        super(Basic_RelativePositionHead, self).__init__()
        self.classifier = torch.nn.Linear(D_in*2,D_out)

    def forward(self, x):
                
        N,_ = x.shape
        # combining two representation (batch is [bs,ch,h,w ])
        x = torch.stack([torch.cat((x[idx,:],x[idx+1,:]))
                     for idx in range(0,N,2)], dim=0).cuda()
        
        #linear output with 8 outpts(directions)
        y_pred = self.classifier(x)
        return y_pred



learning_rate=0.0001
batch_size=32
dtype = torch.float32
resize=160
split=2.0
num_classes=8

#just ToTensor before pathch
transform_train= transforms.Compose([          transforms.RandomCrop(320),
                                               transforms.ToTensor()])



#after patch transformation
transform_after_patch= transforms.Compose([    transforms.ToPILImage(),
                                               transforms.Resize(resize),
                                               transforms.ToTensor(),
                                               transforms.Lambda(lambda x: torch.cat([x, x, x], 0)),
                                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])                                 

cheXpert_train_dataset, dataloader = chexpert_load("CheXpert-v1.0-small/train.csv",transform_train,batch_size)



model=models.densenet121(num_classes=num_classes)
#model.classifier=RelativePositionHead(1024,num_classes)
model.classifier=Basic_RelativePositionHead(1024,num_classes)
model=model.to(device=device)


optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)
criterion =torch.nn.CrossEntropyLoss().cuda()
#criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weights).cuda()

num_epochs=1
for epoch in range(num_epochs):
    for i,  (images, observations) in enumerate(dataloader):   # Load a batch of images with its (index, data, class)
        
        
        patcher = patch.Patch(images,split=split,show=False)
        patches, labels = patcher()
        
        patches = torch.stack([transform_after_patch(x_i) 
                     for i, x_i in enumerate(torch.unbind(patches, dim=0))], dim=0)
        
        
        patches = patches.to(device=device,dtype=dtype)
        labels = torch.from_numpy(labels)
        labels = labels.long()
        labels = labels.to(device=device,dtype=torch.long)
        #print("patches ",patches.shape)

        outputs = model(patches)                             # Forward pass: compute the output class given a image
        
        #print("model outputs ",outputs.shape)

        loss = criterion(outputs, labels)           # Compute the loss: difference between the output class and the pre-given label

        optimizer.zero_grad()                             # Intialize the hidden weight to all zeros
        loss.backward()                                   # Backward pass: compute the weight
        optimizer.step()                                  # Optimizer: update the weights of hidden nodes
        
        
        if (i+1) % 50 == 0:                              # Logging
            print('Epoch [%d/%d], Step [%d/%d], Loss: %.4f'
#                  %(epoch+1, num_epochs, i+1, len(cheXpert_train_dataset)//batch_size, loss))

print('training done')



from google.colab import files

grid_crop_size=225
patch_crop_size=64

file_name = F"relative_position_split{split}_epoch{num_epochs}_batch{batch_size}_patch_resize{resize}.pth"
print(file_name)

PATH=F"/content/gdrive/My Drive/summerthesis/saved_model/{file_name}" 
#torch.save(model.state_dict(), file_name)
#print('saved model to colab')
#files.download(file_name)
#print('saved model to local pc')

torch.save(model.state_dict(), PATH)
print('saved  model to google drive')



num_classe=22
file_name_p_set = F"permutation_set_{num_classe}.pt"
file_name_p_set