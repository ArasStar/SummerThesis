{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"self_supervised_relative_pos.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"XkdT3f6Qosob","colab_type":"code","outputId":"03df32d9-3eac-463f-c778-cdfffef0b4ef","executionInfo":{"status":"ok","timestamp":1560502420691,"user_tz":-60,"elapsed":332362,"user":{"displayName":"Aras Yıldız","photoUrl":"","userId":"09645095620751874495"}},"colab":{"base_uri":"https://localhost:8080/","height":156}},"source":["%reload_ext autoreload\n","%autoreload 2\n","%matplotlib inline\n","\n","#DOWNLOAD THE DATA\n","\n","from google.colab import drive\n","import zipfile\n","\n","#MOUNT GDRIVE: DOWNLOAD DATA AND FILTERED LABELS\n","drive.mount('/content/gdrive',force_remount=True)\n","\n","# UNZIP ZIP\n","print (\"Uncompressing zip file\")\n","zip_ref = zipfile.ZipFile('/content/gdrive/My Drive/CheXpert-v1.0-small.zip', 'r')\n","zip_ref.extractall()\n","zip_ref.close()\n","print(\"downloaded files\")"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n","Uncompressing zip file\n","downloaded files\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6DVqHA9U578j","colab_type":"code","colab":{}},"source":["import sys #For Patch lib\n","sys.path.append(\"gdrive/My Drive/summerthesis/patch\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-wbWXXYaqUsk","colab_type":"code","colab":{}},"source":["import os#for CUDA tracking\n","#from __future__ import print_function, division\n","import torch\n","import pandas as pd\n","from skimage.io import imread\n","#from skimage import io\n","import numpy as np\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","#MODELS\n","import re\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision.models as models\n","import matplotlib.pyplot as plt\n","\n","#Patch\n","import patch\n","\n","\n","# Ignore warnings\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","class CheXpertDataset(Dataset):\n","    \"\"\"Face Landmarks dataset.\"\"\"\n","\n","    def __init__(self, csv_file, root_dir, transform=None):\n","              \n","        super().__init__()\n","\n","        self.observations_frame = pd.read_csv(csv_file)\n","        self.root_dir = root_dir\n","        self.transform = transform\n","        self.list_classes=['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Pleural Effusion']\n","        \n","    def __len__(self):\n","        return len(self.observations_frame)\n","\n","    def __getitem__(self, idx):\n","        \n","        img_name = os.path.join(self.observations_frame.iloc[idx, 0])\n","        image = imread(img_name)\n","        image = transforms.ToPILImage()(image)\n","      \n","\n","        observations=self.observations_frame.loc[idx,self.list_classes]\n","        observations = torch.from_numpy(observations.values.astype(np.float32))\n","        #np.float32()\n","        \n","     \n","        #RETURNING IMAGE AND LABEL SEPERATELY FOR TORCH TRANSFORM LIB\n","      \n","        if self.transform:\n","            \n","            image = self.transform(image)\n","\n","        return image,observations\n","\n","def chexpert_load(csv_file_name,transformation,batch_size):\n","  \n","  cheXpert_dataset = CheXpertDataset(csv_file=csv_file_name,\n","                                     root_dir='not used', transform=transformation)\n","\n","  dataloader = DataLoader(cheXpert_dataset, batch_size=batch_size,shuffle=True)\n","\n","  return cheXpert_dataset,dataloader\n","\n","\n","\n","use_cuda = True\n","if use_cuda and torch.cuda.is_available():\n","    device = torch.device('cuda')\n","else:\n","    print(\"CUDA didn't work\")\n","    device = torch.device('cpu')\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qEeB4hXUItd8","colab_type":"code","outputId":"08f5ff01-c7ba-4adf-a950-594e7334502a","executionInfo":{"status":"ok","timestamp":1560170514674,"user_tz":-60,"elapsed":1352,"user":{"displayName":"Aras Yıldız","photoUrl":"","userId":"09645095620751874495"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["x=torch.ones(16,1024)\n","\n","x = torch.stack([torch.cat((x[idx,:],x[idx+1,:]))\n","                     for idx in range(0,16,2)], dim=0)\n","\n","print(x.shape)\n","  \n","\n","  "],"execution_count":0,"outputs":[{"output_type":"stream","text":["torch.Size([8, 2048])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"D0zKabu4aSoR","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hONznMAJ_8wi","colab_type":"code","colab":{}},"source":["#HOW TO USE RES BLOCK AT THE END AS A Class there operations between features and classifier that causes dimension conflict\n","#LOSS FUNC JUST A 8 WAY SOFTMAX\n","\n","class RelativePositionHead(torch.nn.Module):\n","    def __init__(self, D_in, D_out=8):\n","        \"\"\"\n","        In the constructor we instantiate two nn.Linear modules and assign them as\n","        member variables.\n","        \"\"\"\n","        super(RelativePositionHead, self).__init__()\n","        self.res_block1 = models.resnet.BasicBlock(D_in,512)\n","        self.res_block2 = models.resnet.BasicBlock(512,512)\n","        self.classifier = torch.nn.Linear(512,D_out)\n","\n","    def forward(self, x):\n","        \n","        #print(x.shape)\n","        x = self.res_block1(x)\n","        x = self.res_block2(x)\n","        \n","        _,N,_,_ = x.shape\n","        # combining two representation (batch is [bs,ch,h,w ])\n","        x = torch.stack([torch.cat((x[idx,:,:,:],x[idx+1,:,:,:]))\n","                     for idx in range(0,N,2)], dim=0)\n","        \n","        #linear output with 8 outpts(directions)\n","        y_pred = self.classifier(x)\n","        return y_pred\n","\n","      \n","      \n","class Basic_RelativePositionHead(torch.nn.Module):\n","    def __init__(self, D_in, D_out=8):\n","        \"\"\"\n","        No task head just concating what comes out just before default classifer then applying linear\n","        In the constructor we instantiate two nn.Linear modules and assign them as\n","        member variables.\n","        \"\"\"\n","        super(Basic_RelativePositionHead, self).__init__()\n","        self.classifier = torch.nn.Linear(D_in*2,D_out)\n","\n","    def forward(self, x):\n","                \n","        N,_ = x.shape\n","        # combining two representation (batch is [bs,ch,h,w ])\n","        x = torch.stack([torch.cat((x[idx,:],x[idx+1,:]))\n","                     for idx in range(0,N,2)], dim=0).cuda()\n","        \n","        #linear output with 8 outpts(directions)\n","        y_pred = self.classifier(x)\n","        return y_pred\n","    \n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ytxmo67BbR33","colab_type":"code","colab":{}},"source":["  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"68j43goLqU1O","colab_type":"code","outputId":"61a23d8e-3c69-4a17-a71c-41eaa8ad68ce","executionInfo":{"status":"ok","timestamp":1560345456701,"user_tz":-60,"elapsed":1265857,"user":{"displayName":"Aras Yıldız","photoUrl":"","userId":"09645095620751874495"}},"colab":{"base_uri":"https://localhost:8080/","height":1700}},"source":["learning_rate=0.0001\n","batch_size=32\n","dtype = torch.float32\n","resize=160\n","split=2.0\n","num_classes=8\n","\n","#just ToTensor before pathch\n","transform_train= transforms.Compose([          transforms.RandomCrop(320),\n","                                               transforms.ToTensor()])\n","\n","\n","\n","#after patch transformation\n","transform_after_patch= transforms.Compose([    transforms.ToPILImage(),\n","                                               transforms.Resize(resize),\n","                                               transforms.ToTensor(),\n","                                               transforms.Lambda(lambda x: torch.cat([x, x, x], 0)),\n","                                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])                                 \n","\n","cheXpert_train_dataset, dataloader = chexpert_load(\"CheXpert-v1.0-small/train.csv\",transform_train,batch_size)\n","\n","\n","\n","model=models.densenet121(num_classes=num_classes)\n","#model.classifier=RelativePositionHead(1024,num_classes)\n","model.classifier=Basic_RelativePositionHead(1024,num_classes)\n","model=model.to(device=device)\n","\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","criterion =torch.nn.CrossEntropyLoss().cuda()\n","#criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weights).cuda()\n","\n","num_epochs=1\n","for epoch in range(num_epochs):\n","    for i,  (images, observations) in enumerate(dataloader):   # Load a batch of images with its (index, data, class)\n","        \n","        \n","        patcher = patch.Patch(images,split=split,show=False)\n","        patches, labels = patcher()\n","        \n","        patches = torch.stack([transform_after_patch(x_i) \n","                     for i, x_i in enumerate(torch.unbind(patches, dim=0))], dim=0)\n","        \n","        \n","        patches = patches.to(device=device,dtype=dtype)\n","        labels = torch.from_numpy(labels)\n","        labels = labels.long()\n","        labels = labels.to(device=device,dtype=torch.long)\n","        #print(\"patches \",patches.shape)\n","\n","        outputs = model(patches)                             # Forward pass: compute the output class given a image\n","        \n","        #print(\"model outputs \",outputs.shape)\n","\n","        loss = criterion(outputs, labels)           # Compute the loss: difference between the output class and the pre-given label\n","\n","        optimizer.zero_grad()                             # Intialize the hidden weight to all zeros\n","        loss.backward()                                   # Backward pass: compute the weight\n","        optimizer.step()                                  # Optimizer: update the weights of hidden nodes\n","        \n","        \n","        if (i+1) % 50 == 0:                              # Logging\n","            print('Epoch [%d/%d], Step [%d/%d], Loss: %.4f'\n","                 %(epoch+1, num_epochs, i+1, len(cheXpert_train_dataset)//batch_size, loss))\n","\n","print('training done')\n","\n","\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch [1/1], Step [50/6981], Loss: 1.0804\n","Epoch [1/1], Step [100/6981], Loss: 0.7231\n","Epoch [1/1], Step [150/6981], Loss: 0.4373\n","Epoch [1/1], Step [200/6981], Loss: 0.2776\n","Epoch [1/1], Step [250/6981], Loss: 0.1321\n","Epoch [1/1], Step [300/6981], Loss: 0.1396\n","Epoch [1/1], Step [350/6981], Loss: 0.1790\n","Epoch [1/1], Step [400/6981], Loss: 0.1226\n","Epoch [1/1], Step [450/6981], Loss: 0.1488\n","Epoch [1/1], Step [500/6981], Loss: 0.1429\n","Epoch [1/1], Step [550/6981], Loss: 0.1590\n","Epoch [1/1], Step [600/6981], Loss: 0.1474\n","Epoch [1/1], Step [650/6981], Loss: 0.0385\n","Epoch [1/1], Step [700/6981], Loss: 0.1629\n","Epoch [1/1], Step [750/6981], Loss: 0.0536\n","Epoch [1/1], Step [800/6981], Loss: 0.1749\n","Epoch [1/1], Step [850/6981], Loss: 0.0619\n","Epoch [1/1], Step [900/6981], Loss: 0.1592\n","Epoch [1/1], Step [950/6981], Loss: 0.0727\n","Epoch [1/1], Step [1000/6981], Loss: 0.2276\n","Epoch [1/1], Step [1050/6981], Loss: 0.0467\n","Epoch [1/1], Step [1100/6981], Loss: 0.0715\n","Epoch [1/1], Step [1150/6981], Loss: 0.0255\n","Epoch [1/1], Step [1200/6981], Loss: 0.0136\n","Epoch [1/1], Step [1250/6981], Loss: 0.0441\n","Epoch [1/1], Step [1300/6981], Loss: 0.0838\n","Epoch [1/1], Step [1350/6981], Loss: 0.1417\n","Epoch [1/1], Step [1400/6981], Loss: 0.0214\n","Epoch [1/1], Step [1450/6981], Loss: 0.0482\n","Epoch [1/1], Step [1500/6981], Loss: 0.0628\n","Epoch [1/1], Step [1550/6981], Loss: 0.0155\n","Epoch [1/1], Step [1600/6981], Loss: 0.1132\n","Epoch [1/1], Step [1650/6981], Loss: 0.1061\n","Epoch [1/1], Step [1700/6981], Loss: 0.0653\n","Epoch [1/1], Step [1750/6981], Loss: 0.0303\n","Epoch [1/1], Step [1800/6981], Loss: 0.0292\n","Epoch [1/1], Step [1850/6981], Loss: 0.1521\n","Epoch [1/1], Step [1900/6981], Loss: 0.3774\n","Epoch [1/1], Step [1950/6981], Loss: 0.0356\n","Epoch [1/1], Step [2000/6981], Loss: 0.0156\n","Epoch [1/1], Step [2050/6981], Loss: 0.0463\n","Epoch [1/1], Step [2100/6981], Loss: 0.0084\n","Epoch [1/1], Step [2150/6981], Loss: 0.0456\n","Epoch [1/1], Step [2200/6981], Loss: 0.0504\n","Epoch [1/1], Step [2250/6981], Loss: 0.1854\n","Epoch [1/1], Step [2300/6981], Loss: 0.0084\n","Epoch [1/1], Step [2350/6981], Loss: 0.0347\n","Epoch [1/1], Step [2400/6981], Loss: 0.0697\n","Epoch [1/1], Step [2450/6981], Loss: 0.1958\n","Epoch [1/1], Step [2500/6981], Loss: 0.0167\n","Epoch [1/1], Step [2550/6981], Loss: 0.0196\n","Epoch [1/1], Step [2600/6981], Loss: 0.0201\n","Epoch [1/1], Step [2650/6981], Loss: 0.0124\n","Epoch [1/1], Step [2700/6981], Loss: 0.1273\n","Epoch [1/1], Step [2750/6981], Loss: 0.0339\n","Epoch [1/1], Step [2800/6981], Loss: 0.0135\n","Epoch [1/1], Step [2850/6981], Loss: 0.3544\n","Epoch [1/1], Step [2900/6981], Loss: 0.0772\n","Epoch [1/1], Step [2950/6981], Loss: 0.0177\n","Epoch [1/1], Step [3000/6981], Loss: 0.0593\n","Epoch [1/1], Step [3050/6981], Loss: 0.0167\n","Epoch [1/1], Step [3100/6981], Loss: 0.1604\n","Epoch [1/1], Step [3150/6981], Loss: 0.0064\n","Epoch [1/1], Step [3200/6981], Loss: 0.0144\n","Epoch [1/1], Step [3250/6981], Loss: 0.0085\n","Epoch [1/1], Step [3300/6981], Loss: 0.0128\n","Epoch [1/1], Step [3350/6981], Loss: 0.0556\n","Epoch [1/1], Step [3400/6981], Loss: 0.0294\n","Epoch [1/1], Step [3450/6981], Loss: 0.0507\n","Epoch [1/1], Step [3500/6981], Loss: 0.0081\n","Epoch [1/1], Step [3550/6981], Loss: 0.0071\n","Epoch [1/1], Step [3600/6981], Loss: 0.0217\n","Epoch [1/1], Step [3650/6981], Loss: 0.0052\n","Epoch [1/1], Step [3700/6981], Loss: 0.0179\n","Epoch [1/1], Step [3750/6981], Loss: 0.0130\n","Epoch [1/1], Step [3800/6981], Loss: 0.0469\n","Epoch [1/1], Step [3850/6981], Loss: 0.0102\n","Epoch [1/1], Step [3900/6981], Loss: 0.0109\n","Epoch [1/1], Step [3950/6981], Loss: 0.0119\n","Epoch [1/1], Step [4000/6981], Loss: 0.0165\n","Epoch [1/1], Step [4050/6981], Loss: 0.0363\n","Epoch [1/1], Step [4100/6981], Loss: 0.0115\n","Epoch [1/1], Step [4150/6981], Loss: 0.0224\n","Epoch [1/1], Step [4200/6981], Loss: 0.0131\n","Epoch [1/1], Step [4250/6981], Loss: 0.0534\n","Epoch [1/1], Step [4300/6981], Loss: 0.0051\n","Epoch [1/1], Step [4350/6981], Loss: 0.0095\n","Epoch [1/1], Step [4400/6981], Loss: 0.0234\n","Epoch [1/1], Step [4450/6981], Loss: 0.0128\n","Epoch [1/1], Step [4500/6981], Loss: 0.0059\n","Epoch [1/1], Step [4550/6981], Loss: 0.0521\n","Epoch [1/1], Step [4600/6981], Loss: 0.0042\n","Epoch [1/1], Step [4650/6981], Loss: 0.0086\n","Epoch [1/1], Step [4700/6981], Loss: 0.0056\n","Epoch [1/1], Step [4750/6981], Loss: 0.0122\n","Epoch [1/1], Step [4800/6981], Loss: 0.0555\n","Epoch [1/1], Step [4850/6981], Loss: 0.0110\n","Epoch [1/1], Step [4900/6981], Loss: 0.0021\n","Epoch [1/1], Step [4950/6981], Loss: 0.0020\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WHGPR9eArMeF","colab_type":"code","outputId":"bd9722a8-4422-4b88-e1ce-5a233930f62d","executionInfo":{"status":"ok","timestamp":1560444974317,"user_tz":-60,"elapsed":1272,"user":{"displayName":"Aras Yıldız","photoUrl":"","userId":"09645095620751874495"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":[""],"execution_count":9,"outputs":[{"output_type":"stream","text":["saved to colab files\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8QJBRkMjqU8J","colab_type":"code","colab":{}},"source":["from google.colab import files\n","\n","grid_crop_size=225\n","patch_crop_size=64\n","\n","file_name = F\"relative_position_split{split}_epoch{num_epochs}_batch{batch_size}_patch_resize{resize}.pth\"\n","print(file_name)\n","\n","PATH=F\"/content/gdrive/My Drive/summerthesis/saved_model/{file_name}\" \n","#torch.save(model.state_dict(), file_name)\n","#print('saved model to colab')\n","#files.download(file_name)\n","#print('saved model to local pc')\n","\n","torch.save(model.state_dict(), PATH)\n","print('saved  model to google drive')\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"A8_y7jLOqVDa","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"B7j61ZTTpI8X","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"d97f2d7f-d177-4826-938b-0de44f011351","executionInfo":{"status":"ok","timestamp":1560946788202,"user_tz":-60,"elapsed":588,"user":{"displayName":"Aras Yıldız","photoUrl":"","userId":"09645095620751874495"}}},"source":["num_classe=22\n","file_name_p_set = F\"permutation_set_{num_classe}.pt\"\n","file_name_p_set\n"],"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'permutation_set_22.pt'"]},"metadata":{"tags":[]},"execution_count":1}]}]}